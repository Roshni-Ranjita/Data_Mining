{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7943a193-d5fe-4200-9a01-08d1df09a9fe",
   "metadata": {},
   "source": [
    "### GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e688355-c63e-4bf1-98f4-57f78828a023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 1.9456 | Train Acc: 16.53%\n",
      "Epoch 10 | Loss: 0.2910 | Train Acc: 93.35%\n",
      "Epoch 20 | Loss: 0.0755 | Train Acc: 98.59%\n",
      "Epoch 30 | Loss: 0.0477 | Train Acc: 99.19%\n",
      "Epoch 40 | Loss: 0.0404 | Train Acc: 99.19%\n",
      "Epoch 50 | Loss: 0.0360 | Train Acc: 99.80%\n",
      "Epoch 60 | Loss: 0.0449 | Train Acc: 99.60%\n",
      "Epoch 70 | Loss: 0.0396 | Train Acc: 99.40%\n",
      "Epoch 80 | Loss: 0.0340 | Train Acc: 100.00%\n",
      "Epoch 90 | Loss: 0.0311 | Train Acc: 99.80%\n",
      "Epoch 100 | Loss: 0.0318 | Train Acc: 100.00%\n",
      "Epoch 110 | Loss: 0.0306 | Train Acc: 100.00%\n",
      "Epoch 120 | Loss: 0.0288 | Train Acc: 99.80%\n",
      "Epoch 130 | Loss: 0.0322 | Train Acc: 99.60%\n",
      "Epoch 140 | Loss: 0.0270 | Train Acc: 100.00%\n",
      "Epoch 150 | Loss: 0.0279 | Train Acc: 99.80%\n",
      "Epoch 160 | Loss: 0.0284 | Train Acc: 99.80%\n",
      "Epoch 170 | Loss: 0.0271 | Train Acc: 99.60%\n",
      "Epoch 180 | Loss: 0.0247 | Train Acc: 99.80%\n",
      "Epoch 190 | Loss: 0.0216 | Train Acc: 100.00%\n",
      "Submission saved to: E:\\Data_Mining\\your_team_submission_GCN.txt\n",
      "2051 6\n",
      "1788 3\n",
      "1233 0\n",
      "926 5\n",
      "2053 1\n",
      "2083 3\n",
      "2370 2\n",
      "1306 4\n",
      "1354 6\n",
      "603 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "import scipy.sparse as sp\n",
    "import json\n",
    "\n",
    "# =========================\n",
    "# 1. Load and Preprocess Data\n",
    "# =========================\n",
    "\n",
    "# Load adjacency matrix, features, labels, and splits\n",
    "adj = sp.load_npz('data/data/adj.npz')\n",
    "feat = np.load('data/data/features.npy')\n",
    "labels = np.load('data/data/labels.npy')\n",
    "splits = json.load(open('data/data/splits.json'))\n",
    "idx_train, idx_test = splits['idx_train'], splits['idx_test']\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x = torch.from_numpy(feat).float()\n",
    "edge_index, _ = from_scipy_sparse_matrix(adj)\n",
    "\n",
    "# Initialize all labels as -1 and set only train labels\n",
    "y = torch.full((x.shape[0],), -1, dtype=torch.long)\n",
    "y[idx_train] = torch.from_numpy(labels).long()\n",
    "\n",
    "# Convert indices to tensors\n",
    "idx_train = torch.tensor(idx_train, dtype=torch.long)\n",
    "idx_test = torch.tensor(idx_test, dtype=torch.long)\n",
    "\n",
    "# Filter training indices to only valid labels\n",
    "idx_train = idx_train[y[idx_train] != -1]\n",
    "\n",
    "# =========================\n",
    "# 2. Define GCN Model\n",
    "# =========================\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim, num_classes, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, num_classes)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# =========================\n",
    "# 3. Training Setup\n",
    "# =========================\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x, edge_index, y = x.to(device), edge_index.to(device), y.to(device)\n",
    "idx_train = idx_train.to(device)\n",
    "idx_test = idx_test.to(device)\n",
    "\n",
    "num_features = x.shape[1]\n",
    "num_classes = y[idx_train].max().item() + 1  # number of classes in train\n",
    "\n",
    "model = GCN(num_features, hidden_dim=64, num_classes=num_classes, dropout=0.5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# =========================\n",
    "# 4. Training Loop\n",
    "# =========================\n",
    "\n",
    "best_acc = 0\n",
    "best_pred = None\n",
    "\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(x, edge_index)\n",
    "    loss = criterion(out[idx_train], y[idx_train])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Evaluate on train set\n",
    "    model.eval()\n",
    "    _, pred = out.max(dim=1)\n",
    "    correct = int((pred[idx_train] == y[idx_train]).sum())\n",
    "    acc = correct / len(idx_train)\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_pred = pred.detach().cpu().numpy()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch} | Loss: {loss.item():.4f} | Train Acc: {acc*100:.2f}%\")\n",
    "\n",
    "# =========================\n",
    "# 5. Predict and Save Results\n",
    "# =========================\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(x, edge_index)\n",
    "    pred = out.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "\n",
    "# Save in current working directory\n",
    "output_dir = ''  \n",
    "output_path = os.path.join(output_dir, 'your_team_submission_GCN.txt')\n",
    "\n",
    "# Save the file\n",
    "np.savetxt(output_path, submission, fmt='%d %d')\n",
    "\n",
    "# Confirm and preview results\n",
    "print(f\"Submission saved to: {os.path.abspath(output_path)}\")\n",
    "with open(output_path, 'r') as f:\n",
    "    for _ in range(10):\n",
    "        print(f.readline().strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a5d343-930b-4f04-88a1-b95170a3d20b",
   "metadata": {},
   "source": [
    "### GraphSage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08ec9370-da3d-4d27-8bc5-807c92fe4fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 1.9266 | Train Acc: 27.82%\n",
      "Epoch 10 | Loss: 0.0900 | Train Acc: 97.38%\n",
      "Epoch 20 | Loss: 0.0064 | Train Acc: 100.00%\n",
      "Epoch 30 | Loss: 0.0046 | Train Acc: 99.80%\n",
      "Epoch 40 | Loss: 0.0060 | Train Acc: 100.00%\n",
      "Epoch 50 | Loss: 0.0081 | Train Acc: 100.00%\n",
      "Epoch 60 | Loss: 0.0106 | Train Acc: 100.00%\n",
      "Epoch 70 | Loss: 0.0132 | Train Acc: 100.00%\n",
      "Epoch 80 | Loss: 0.0111 | Train Acc: 100.00%\n",
      "Epoch 90 | Loss: 0.0101 | Train Acc: 100.00%\n",
      "Epoch 100 | Loss: 0.0133 | Train Acc: 100.00%\n",
      "Epoch 110 | Loss: 0.0104 | Train Acc: 100.00%\n",
      "Epoch 120 | Loss: 0.0079 | Train Acc: 100.00%\n",
      "Epoch 130 | Loss: 0.0093 | Train Acc: 100.00%\n",
      "Epoch 140 | Loss: 0.0101 | Train Acc: 100.00%\n",
      "Epoch 150 | Loss: 0.0079 | Train Acc: 100.00%\n",
      "Epoch 160 | Loss: 0.0094 | Train Acc: 100.00%\n",
      "Epoch 170 | Loss: 0.0069 | Train Acc: 100.00%\n",
      "Epoch 180 | Loss: 0.0080 | Train Acc: 100.00%\n",
      "Epoch 190 | Loss: 0.0072 | Train Acc: 100.00%\n",
      "Submission saved to: E:\\Data_Mining\\your_team_submission_sage.txt\n",
      "2051 6\n",
      "1788 3\n",
      "1233 0\n",
      "926 5\n",
      "2053 1\n",
      "2083 3\n",
      "2370 2\n",
      "1306 4\n",
      "1354 6\n",
      "603 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "import scipy.sparse as sp\n",
    "import json\n",
    "\n",
    "# =========================\n",
    "# 1. Load and Preprocess Data\n",
    "# =========================\n",
    "\n",
    "# Load adjacency matrix, features, labels, and splits\n",
    "adj = sp.load_npz('data/data/adj.npz')\n",
    "feat = np.load('data/data/features.npy')\n",
    "labels = np.load('data/data/labels.npy')\n",
    "splits = json.load(open('data/data/splits.json'))\n",
    "idx_train, idx_test = splits['idx_train'], splits['idx_test']\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x = torch.from_numpy(feat).float()\n",
    "edge_index, _ = from_scipy_sparse_matrix(adj)\n",
    "\n",
    "# Initialize all labels as -1 and assign labels for training nodes\n",
    "y = torch.full((x.shape[0],), -1, dtype=torch.long)\n",
    "y[idx_train] = torch.from_numpy(labels).long()\n",
    "\n",
    "# Convert indices to tensors\n",
    "idx_train = torch.tensor(idx_train, dtype=torch.long)\n",
    "idx_test = torch.tensor(idx_test, dtype=torch.long)\n",
    "\n",
    "# Filter invalid label indices\n",
    "idx_train = idx_train[y[idx_train] != -1]\n",
    "\n",
    "# =========================\n",
    "# 2. Define GraphSAGE Model\n",
    "# =========================\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# =========================\n",
    "# 3. Training Setup\n",
    "# =========================\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x, edge_index, y = x.to(device), edge_index.to(device), y.to(device)\n",
    "idx_train = idx_train.to(device)\n",
    "idx_test = idx_test.to(device)\n",
    "\n",
    "num_features = x.shape[1]\n",
    "num_classes = y[idx_train].max().item() + 1\n",
    "\n",
    "model = GraphSAGE(num_features, hidden_channels=64, out_channels=num_classes, dropout=0.5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# =========================\n",
    "# 4. Training Loop\n",
    "# =========================\n",
    "\n",
    "best_acc = 0\n",
    "best_pred = None\n",
    "\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(x, edge_index)\n",
    "    loss = criterion(out[idx_train], y[idx_train])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Train accuracy\n",
    "    model.eval()\n",
    "    _, pred = out.max(dim=1)\n",
    "    correct = int((pred[idx_train] == y[idx_train]).sum())\n",
    "    acc = correct / len(idx_train)\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_pred = pred.detach().cpu().numpy()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch} | Loss: {loss.item():.4f} | Train Acc: {acc*100:.2f}%\")\n",
    "\n",
    "# =========================\n",
    "# 5. Predict and Save Results\n",
    "# =========================\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(x, edge_index)\n",
    "    pred = out.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "# Prepare submission\n",
    "# Save in current working directory\n",
    "output_dir = ''  # leave empty to save in current script directory\n",
    "output_path = os.path.join(output_dir, 'your_team_submission_sage.txt')\n",
    "\n",
    "# Save the file\n",
    "np.savetxt(output_path, submission, fmt='%d %d')\n",
    "\n",
    "# Confirm and preview results\n",
    "print(f\"Submission saved to: {os.path.abspath(output_path)}\")\n",
    "with open(output_path, 'r') as f:\n",
    "    for _ in range(10):\n",
    "        print(f.readline().strip())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8683ef8d-5fc4-4521-91bf-61534e3a867b",
   "metadata": {},
   "source": [
    "### GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "251b51b8-2ef5-4097-92af-f61b530fcae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 1.9975 | Train Acc: 15.52%\n",
      "Epoch 10 | Loss: 1.1594 | Train Acc: 69.56%\n",
      "Epoch 20 | Loss: 0.8810 | Train Acc: 77.42%\n",
      "Epoch 30 | Loss: 0.7279 | Train Acc: 77.62%\n",
      "Epoch 40 | Loss: 0.6735 | Train Acc: 78.23%\n",
      "Epoch 50 | Loss: 0.6071 | Train Acc: 80.44%\n",
      "Epoch 60 | Loss: 0.6539 | Train Acc: 79.84%\n",
      "Epoch 70 | Loss: 0.6094 | Train Acc: 83.27%\n",
      "Epoch 80 | Loss: 0.5884 | Train Acc: 81.25%\n",
      "Epoch 90 | Loss: 0.5487 | Train Acc: 81.85%\n",
      "Epoch 100 | Loss: 0.5980 | Train Acc: 80.04%\n",
      "Epoch 110 | Loss: 0.6034 | Train Acc: 80.04%\n",
      "Epoch 120 | Loss: 0.5743 | Train Acc: 81.85%\n",
      "Epoch 130 | Loss: 0.5121 | Train Acc: 84.27%\n",
      "Epoch 140 | Loss: 0.4923 | Train Acc: 82.66%\n",
      "Epoch 150 | Loss: 0.5141 | Train Acc: 82.86%\n",
      "Epoch 160 | Loss: 0.5359 | Train Acc: 82.06%\n",
      "Epoch 170 | Loss: 0.5571 | Train Acc: 80.65%\n",
      "Epoch 180 | Loss: 0.5273 | Train Acc: 82.86%\n",
      "Epoch 190 | Loss: 0.5612 | Train Acc: 81.25%\n",
      "Submission saved to: E:\\Data_Mining\\your_team_submission_gat.txt\n",
      "2051 6\n",
      "1788 3\n",
      "1233 0\n",
      "926 5\n",
      "2053 1\n",
      "2083 3\n",
      "2370 2\n",
      "1306 4\n",
      "1354 6\n",
      "603 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "import scipy.sparse as sp\n",
    "import json\n",
    "\n",
    "# =========================\n",
    "# 1. Load and Preprocess Data\n",
    "# =========================\n",
    "\n",
    "# Load adjacency matrix, features, labels, and splits\n",
    "adj = sp.load_npz('data/data/adj.npz')\n",
    "feat = np.load('data/data/features.npy')\n",
    "labels = np.load('data/data/labels.npy')\n",
    "splits = json.load(open('data/data/splits.json'))\n",
    "idx_train, idx_test = splits['idx_train'], splits['idx_test']\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x = torch.from_numpy(feat).float()\n",
    "edge_index, _ = from_scipy_sparse_matrix(adj)\n",
    "\n",
    "# Initialize label tensor with -1\n",
    "y = torch.full((x.shape[0],), -1, dtype=torch.long)\n",
    "y[idx_train] = torch.from_numpy(labels).long()\n",
    "\n",
    "# Convert index arrays to torch tensors\n",
    "idx_train = torch.tensor(idx_train, dtype=torch.long)\n",
    "idx_test = torch.tensor(idx_test, dtype=torch.long)\n",
    "\n",
    "# Remove any invalid label indices from training set\n",
    "idx_train = idx_train[y[idx_train] != -1]\n",
    "\n",
    "# =========================\n",
    "# 2. Define GAT Model\n",
    "# =========================\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=8, dropout=0.6):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n",
    "        self.gat2 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=dropout)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# =========================\n",
    "# 3. Training Setup\n",
    "# =========================\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x, edge_index, y = x.to(device), edge_index.to(device), y.to(device)\n",
    "idx_train = idx_train.to(device)\n",
    "idx_test = idx_test.to(device)\n",
    "\n",
    "num_features = x.shape[1]\n",
    "num_classes = y[idx_train].max().item() + 1\n",
    "\n",
    "model = GAT(num_features, hidden_channels=8, out_channels=num_classes, heads=8, dropout=0.6).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# =========================\n",
    "# 4. Training Loop\n",
    "# =========================\n",
    "\n",
    "best_acc = 0\n",
    "best_pred = None\n",
    "\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(x, edge_index)\n",
    "    loss = criterion(out[idx_train], y[idx_train])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Evaluate on train set\n",
    "    model.eval()\n",
    "    _, pred = out.max(dim=1)\n",
    "    correct = int((pred[idx_train] == y[idx_train]).sum())\n",
    "    acc = correct / len(idx_train)\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_pred = pred.detach().cpu().numpy()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch} | Loss: {loss.item():.4f} | Train Acc: {acc*100:.2f}%\")\n",
    "\n",
    "# =========================\n",
    "# 5. Predict and Save Results\n",
    "# =========================\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(x, edge_index)\n",
    "    pred = out.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "# Prepare submission\n",
    "output_dir = ''  # leave empty to save in current script directory\n",
    "output_path = os.path.join(output_dir, 'your_team_submission_gat.txt')\n",
    "\n",
    "# Save the file\n",
    "np.savetxt(output_path, submission, fmt='%d %d')\n",
    "\n",
    "# Confirm and preview results\n",
    "print(f\"Submission saved to: {os.path.abspath(output_path)}\")\n",
    "with open(output_path, 'r') as f:\n",
    "    for _ in range(10):\n",
    "        print(f.readline().strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2406f363-2339-4279-b606-37f06c8b5550",
   "metadata": {},
   "source": [
    "### Baseline MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c5bd140-c401-411a-8f5b-4709b9a7e020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 1.9420 | Train Acc: 16.53%\n",
      "Epoch 10 | Loss: 0.4451 | Train Acc: 93.15%\n",
      "Epoch 20 | Loss: 0.0798 | Train Acc: 98.59%\n",
      "Epoch 30 | Loss: 0.0367 | Train Acc: 99.19%\n",
      "Epoch 40 | Loss: 0.0248 | Train Acc: 99.60%\n",
      "Epoch 50 | Loss: 0.0272 | Train Acc: 99.40%\n",
      "Epoch 60 | Loss: 0.0261 | Train Acc: 100.00%\n",
      "Epoch 70 | Loss: 0.0252 | Train Acc: 100.00%\n",
      "Epoch 80 | Loss: 0.0282 | Train Acc: 99.80%\n",
      "Epoch 90 | Loss: 0.0293 | Train Acc: 99.60%\n",
      "Epoch 100 | Loss: 0.0243 | Train Acc: 100.00%\n",
      "Epoch 110 | Loss: 0.0183 | Train Acc: 99.80%\n",
      "Epoch 120 | Loss: 0.0225 | Train Acc: 100.00%\n",
      "Epoch 130 | Loss: 0.0191 | Train Acc: 100.00%\n",
      "Epoch 140 | Loss: 0.0193 | Train Acc: 99.80%\n",
      "Epoch 150 | Loss: 0.0185 | Train Acc: 100.00%\n",
      "Epoch 160 | Loss: 0.0277 | Train Acc: 100.00%\n",
      "Epoch 170 | Loss: 0.0161 | Train Acc: 100.00%\n",
      "Epoch 180 | Loss: 0.0170 | Train Acc: 100.00%\n",
      "Epoch 190 | Loss: 0.0176 | Train Acc: 100.00%\n",
      "Submission saved to: E:\\Data_Mining\\your_team_submission_mlp.txt\n",
      "2051 6\n",
      "1788 3\n",
      "1233 0\n",
      "926 5\n",
      "2053 1\n",
      "2083 3\n",
      "2370 2\n",
      "1306 4\n",
      "1354 6\n",
      "603 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "import scipy.sparse as sp\n",
    "import json\n",
    "\n",
    "# =========================\n",
    "# 1. Load and Preprocess Data\n",
    "# =========================\n",
    "\n",
    "# Load adjacency matrix, features, labels, and splits\n",
    "adj = sp.load_npz('data/data/adj.npz')\n",
    "feat = np.load('data/data/features.npy')\n",
    "labels = np.load('data/data/labels.npy')\n",
    "splits = json.load(open('data/data/splits.json'))\n",
    "idx_train, idx_test = splits['idx_train'], splits['idx_test']\n",
    "\n",
    "# Convert features to torch tensor\n",
    "x = torch.from_numpy(feat).float()\n",
    "\n",
    "# Initialize label tensor with -1\n",
    "y = torch.full((x.shape[0],), -1, dtype=torch.long)\n",
    "y[idx_train] = torch.from_numpy(labels).long()\n",
    "\n",
    "# Convert index arrays to torch tensors\n",
    "idx_train = torch.tensor(idx_train, dtype=torch.long)\n",
    "idx_test = torch.tensor(idx_test, dtype=torch.long)\n",
    "\n",
    "# Remove invalid label indices from training set\n",
    "idx_train = idx_train[y[idx_train] != -1]\n",
    "\n",
    "# =========================\n",
    "# 2. Define MLP Model\n",
    "# =========================\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(in_channels, hidden_channels)\n",
    "        self.fc2 = torch.nn.Linear(hidden_channels, out_channels)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# =========================\n",
    "# 3. Training Setup\n",
    "# =========================\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x, y = x.to(device), y.to(device)\n",
    "idx_train = idx_train.to(device)\n",
    "idx_test = idx_test.to(device)\n",
    "\n",
    "num_features = x.shape[1]\n",
    "num_classes = y[idx_train].max().item() + 1\n",
    "\n",
    "model = MLP(num_features, hidden_channels=64, out_channels=num_classes, dropout=0.5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# =========================\n",
    "# 4. Training Loop\n",
    "# =========================\n",
    "\n",
    "best_acc = 0\n",
    "best_pred = None\n",
    "\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(x)\n",
    "    loss = criterion(out[idx_train], y[idx_train])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Evaluate on train set\n",
    "    model.eval()\n",
    "    _, pred = out.max(dim=1)\n",
    "    correct = int((pred[idx_train] == y[idx_train]).sum())\n",
    "    acc = correct / len(idx_train)\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_pred = pred.detach().cpu().numpy()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch} | Loss: {loss.item():.4f} | Train Acc: {acc*100:.2f}%\")\n",
    "\n",
    "# =========================\n",
    "# 5. Predict and Save Results\n",
    "# =========================\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(x)\n",
    "    pred = out.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "# Prepare submission\n",
    "output_dir = ''  # leave empty to save in current script directory\n",
    "output_path = os.path.join(output_dir, 'your_team_submission_mlp.txt')\n",
    "\n",
    "# Save the file\n",
    "np.savetxt(output_path, submission, fmt='%d %d')\n",
    "\n",
    "# Confirm and preview results\n",
    "print(f\"Submission saved to: {os.path.abspath(output_path)}\")\n",
    "with open(output_path, 'r') as f:\n",
    "    for _ in range(10):\n",
    "        print(f.readline().strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088cd0b7-399a-467d-bfea-8720a2d333db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
