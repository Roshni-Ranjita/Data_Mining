{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch Geometric (PyG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch Geometric (PyG): https://pytorch-geometric.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Instllation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#data-handling-of-graphs and understand the meaning of `edge_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_geometric in /opt/anaconda3/lib/python3.12/site-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (3.10.5)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (2024.6.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (5.9.0)\n",
      "Requirement already satisfied: pyparsing in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from torch_geometric) (4.66.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch_geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torch_geometric) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torch_geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->torch_geometric) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code provides an example to use PyG for building GCN to solve the node classification task. We will walk through the code and write code comments in this lecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='data/Citeseer', name='Citeseer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Citeseer()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3327, 3703])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y.max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_hidden, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, num_hidden)\n",
    "        self.conv2 = GCNConv(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 1.7953003644943237\n",
      "Epoch 10: 0.3820640742778778\n",
      "Epoch 20: 0.12834005057811737\n",
      "Epoch 30: 0.06699023395776749\n",
      "Epoch 40: 0.03642746061086655\n",
      "Epoch 50: 0.048827774822711945\n",
      "Epoch 60: 0.03443939611315727\n",
      "Epoch 70: 0.05090121552348137\n",
      "Epoch 80: 0.025061285123229027\n",
      "Epoch 90: 0.036277711391448975\n",
      "Epoch 100: 0.03450305014848709\n",
      "Epoch 110: 0.05213276296854019\n",
      "Epoch 120: 0.033971529453992844\n",
      "Epoch 130: 0.03782632201910019\n",
      "Epoch 140: 0.032948918640613556\n",
      "Epoch 150: 0.032123465090990067\n",
      "Epoch 160: 0.025365522131323814\n",
      "Epoch 170: 0.03311274200677872\n",
      "Epoch 180: 0.044955410063266754\n",
      "Epoch 190: 0.011644215323030949\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device)\n",
    "model = GCN(num_node_features=data.x.shape[1], \n",
    "            num_hidden=16,\n",
    "            num_classes=(data.y.max()+1).item()\n",
    "           ).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch {0}: {1}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6730\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: How to use PyG in our project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, there are only a few more steps we need to do:\n",
    "- we need to convert the provided data into the PyG format.\n",
    "    - PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "adj = sp.load_npz('data/adj.npz')\n",
    "feat  = np.load('data/features.npy')\n",
    "labels = np.load('data/labels.npy')\n",
    "splits = json.load(open('data/splits.json'))\n",
    "idx_train, idx_test = splits['idx_train'], splits['idx_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2480, 2480)\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# what data do we have in this project?\n",
    "\n",
    "# 1. Adjacent matrix: a n x n matrix where n is the number of nodes in this graph\n",
    "print(adj.shape) # 2480 nodes, and each entry of adj indicates whether two nodes are connected or not (0 if disconnected, 1 otherwise)\n",
    "print(adj[0, 1104]) # adj[0, 1104] = 1 indicates node 0 and node 1104 are connected\n",
    "print(adj[1, 1003]) # adj[1, 1003] = 0 indicates node 1 and node 1003 aren't connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2480, 1390)\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 2. feat matrix: a n x d matrix where each row is a d-dimensional feature vector of a node\n",
    "print(feat.shape) # 2480 nodes each containing a 1390-dimensional feature vector\n",
    "print(feat[6])    # the feature vector of node 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496,)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# 3. labels: class labels of training nodes\n",
    "print(labels.shape)  # note: labels contain only the class labels of training nodes\n",
    "print(labels.max() + 1) # There are 7 classes in total, and each training node belongs to one of 7 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['idx_train', 'idx_test'])\n",
      "# train nodes =  496\n",
      "# test nodes =  1984\n"
     ]
    }
   ],
   "source": [
    "# 4. splits: A python dictionary for train-test set split\n",
    "print(splits.keys()) # 'idx_train' includes node index for training, and 'idx_test' includes node index for testing\n",
    "print(\"# train nodes = \", len(splits['idx_train'])) # 496 nodes for training, and \"labels\" above correspond to the class labels of these training nodes\n",
    "print(\"# test nodes = \", len(splits['idx_test']))  # 1984 nodes for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import from_scipy_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = from_scipy_sparse_matrix(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   0,    0,    0,  ..., 2478, 2478, 2479],\n",
       "         [1084, 1104, 1288,  ...,  931,  933,  999]]),\n",
       " tensor([1., 1., 1.,  ..., 1., 1., 1.]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to submit the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pred[idx_test]\n",
    "np.savetxt('submission.txt', preds, fmt='%d')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One intuitive Example using MLP\n",
    "\n",
    "This example is just used to show what is expected in 'submission.txt'. \n",
    "No graph structure (adjacency matrix) will be used, thus only torch functions are needed.\n",
    "Feel free to use torch_geometric when incorporating graph structure in more advanced graph mining algorithms.\n",
    "\n",
    "\n",
    "Remark 1: without using the graph structure (adjacency matrix), this could be suboptimal.\n",
    "\n",
    "Remark 2: see the tutorial \"Introduction to Pytorch\" for MLP construction and training\n",
    "\n",
    "Remark 3: feel free to run this example to see what is expected in 'submission.txt'\n",
    "\n",
    "Remark 4: don't forget to rename your submitted files to '{YourTeamName}_submission.txt' (feel free to pick a fun name for your team!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Linear(nn.Module): # Inheritance torch.nn.Module\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(Linear, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_features, out_features)) \n",
    "        self.bias = nn.Parameter(torch.randn(out_features))\n",
    "    \n",
    "    def forward(self, x): # x is the input\n",
    "        x = x.mm(self.weight) \n",
    "        return x + self.bias\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super(MLP, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.layer1 = Linear(in_features, hidden_features)  # Linear()\n",
    "        self.layer2 = Linear(hidden_features, out_features)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = F.relu(x) # ReLU\n",
    "        return self.layer2(x)\n",
    "\n",
    "train_feats, train_labels = torch.from_numpy(feat[idx_train]).float(), torch.from_numpy(labels).long()\n",
    "data_train = torch.utils.data.TensorDataset(train_feats, train_labels) # wrap tensors into a dataset object\n",
    "feat_dim = train_feats.shape[1]\n",
    "num_classes = labels.max() + 1\n",
    "model = MLP(in_features=feat_dim, hidden_features=256, out_features=num_classes)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, num_epochs=5, learning_rate=1e-3, batch_size=32):\n",
    "    # define an optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=learning_rate, \n",
    "                                 weight_decay=1e-5) # weight_decay is the L2 Regularization\n",
    "    \n",
    "    # Put the data into DataLoader so we can get a batch of data\n",
    "    train_loader = torch.utils.data.DataLoader(data, \n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=True)\n",
    "    # define loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        loss_total = 0 # \n",
    "        for data in train_loader:\n",
    "            # clear the gradient\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            feat, label = data\n",
    "            feat = feat.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            # forward, loss and backward \n",
    "            output = model(feat)\n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "            \n",
    "            # optimize the parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "        loss_total += loss.item() \n",
    "        print('Epoch: {}, Training Loss: {:.4f}'.format(epoch+1, loss_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 42.2957\n",
      "Epoch: 2, Training Loss: 34.0030\n",
      "Epoch: 3, Training Loss: 55.2561\n",
      "Epoch: 4, Training Loss: 30.5589\n",
      "Epoch: 5, Training Loss: 38.9551\n"
     ]
    }
   ],
   "source": [
    "train(model, data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "output = model(torch.from_numpy(feat).float().to(device))\n",
    "pred = output.argmax(1)\n",
    "preds = pred[idx_test]\n",
    "np.savetxt('submission.txt', preds, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
